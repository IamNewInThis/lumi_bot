# src/routes/chat.py
import os
import httpx
from fastapi import APIRouter, Depends, HTTPException
from datetime import datetime
from ..models.chat import ChatRequest, KnowledgeConfirmRequest
from ..auth import get_current_user
from src.rag.utils import get_rag_context
from src.utils.date_utils import calcular_edad, calcular_meses
from ..rag.retriever import supabase
from ..utils.knowledge_detector import KnowledgeDetector
from ..services.knowledge_service import BabyKnowledgeService
from ..utils.knowledge_cache import confirmation_cache

router = APIRouter()
today = datetime.now().strftime("%d/%m/%Y %H:%M")

OPENAI_KEY = os.getenv("OPENAI_API_KEY")
OPENAI_MODEL = os.getenv("OPENAI_MODEL", "gpt-4o")

if not OPENAI_KEY:
    raise RuntimeError("Falta OPENAI_API_KEY en variables de entorno (.env)")

async def get_user_profiles_and_babies(user_id, supabase_client):
    profiles = supabase_client.table("profiles").select("*").eq("id", user_id).execute()
    babies = supabase_client.table("babies").select("*").eq("user_id", user_id).execute()

    # Obtener conocimiento espec√≠fico de todos los beb√©s
    knowledge_by_baby = await BabyKnowledgeService.get_all_user_knowledge(user_id)
    knowledge_context = BabyKnowledgeService.format_knowledge_for_context(knowledge_by_baby)

    profile_texts = [
        f"- Perfil: {p['name']}, fecha de nacimiento {p['birthdate']}, alimentaci√≥n: {p.get('feeding', 'N/A')}"
        for p in profiles.data
    ] if profiles.data else []

    baby_texts = []
    routines_context = ""
    if babies.data:
        for b in babies.data:
            edad_anios = calcular_edad(b["birthdate"])
            edad_meses = calcular_meses(b["birthdate"])
            rutina = b.get("routines")

            baby_texts.append(
                f"- Beb√©: {b['name']}, fecha de nacimiento {b['birthdate']}, "
                f"edad: {edad_anios} a√±os ({edad_meses} meses aprox.), "
                f"alimentaci√≥n: {b.get('feeding', 'N/A')}"
                f"peso: {b.get('weight', 'N/A')} kg, "
                f"altura: {b.get('height', 'N/A')} cm"
            ) 

            # Si no hay rutina, sugerir crear una pidiendo detalles
            if not rutina:
                routines_context += (
                    f"‚ö†Ô∏è El beb√© {b['name']} no tiene rutina registrada. "
                    "Si el usuario pide crear una rutina, primero preg√∫ntale qu√© actividades y horarios quiere incluir. "
                    "Luego organiza la rutina en formato tabla con columnas: Hora | Actividad | Detalles.\n\n"
                )
            else:
                routines_context += (
                    f"‚úÖ El beb√© {b['name']} ya tiene una rutina registrada. "
                    "Si el usuario pide modificarla o revisarla, mu√©strala en formato tabla y sugiere mejoras.\n\n"
                )

    context = ""
    if profile_texts:
        context += "Perfiles:\n" + "\n".join(profile_texts) + "\n\n"
    if baby_texts:
        context += "Beb√©s:\n" + "\n".join(baby_texts) + "\n\n"
    
    # Agregar conocimiento espec√≠fico si existe
    if knowledge_context:
        context += knowledge_context + "\n\n"

    return context.strip(), routines_context.strip()

async def get_conversation_history(user_id, supabase_client, limit_per_role=5):
    """
    Recupera los √∫ltimos mensajes del usuario y del asistente para mantener contexto en la conversaci√≥n.
    """
    user_msgs = supabase_client.table("conversations") \
        .select("*") \
        .eq("user_id", user_id) \
        .eq("role", "user") \
        .order("created_at", desc=True) \
        .limit(limit_per_role) \
        .execute()

    assistant_msgs = supabase_client.table("conversations") \
        .select("*") \
        .eq("user_id", user_id) \
        .eq("role", "assistant") \
        .order("created_at", desc=True) \
        .limit(limit_per_role) \
        .execute()

    # Combinar y ordenar cronol√≥gicamente
    history = (user_msgs.data or []) + (assistant_msgs.data or [])
    history_sorted = sorted(history, key=lambda x: x["created_at"])

    # Convertir al formato que espera OpenAI
    formatted_history = [
        {"role": msg["role"], "content": msg["content"]}
        for msg in history_sorted
    ]

    return formatted_history

@router.post("/api/chat")
async def chat_openai(payload: ChatRequest, user=Depends(get_current_user)):
    if not payload.message.strip():
        raise HTTPException(status_code=400, detail="message required")

    user_id = user["id"]
    
    # üî• NUEVO: Verificar primero si es una respuesta de confirmaci√≥n
    confirmation_response = confirmation_cache.is_confirmation_response(payload.message)
    if confirmation_response is not None and confirmation_cache.has_pending_confirmation(user_id):
        print(f"üéØ Detectada respuesta de confirmaci√≥n: {confirmation_response}")
        
        pending_data = confirmation_cache.get_pending_confirmation(user_id)
        if pending_data:
            if confirmation_response:  # Usuario confirm√≥
                try:
                    saved_items = []
                    
                    for knowledge_item in pending_data["knowledge"]:
                        # Buscar el baby_id basado en el nombre
                        baby_id = await BabyKnowledgeService.find_baby_by_name(
                            user_id, 
                            knowledge_item.get("baby_name", "")
                        )
                        
                        if baby_id:
                            # Preparar datos para guardar
                            knowledge_data = {
                                "category": knowledge_item["category"],
                                "subcategory": knowledge_item.get("subcategory"),
                                "title": knowledge_item["title"],
                                "description": knowledge_item["description"],
                                "importance_level": knowledge_item.get("importance_level", 1)
                            }
                            
                            # Guardar en la base de datos
                            saved_item = await BabyKnowledgeService.save_knowledge(
                                user_id, 
                                baby_id, 
                                knowledge_data
                            )
                            saved_items.append(saved_item)
                    
                    confirmation_cache.clear_pending_confirmation(user_id)
                    
                    response_text = f"‚úÖ ¬°Perfecto! He guardado {len(saved_items)} elemento(s) en el perfil. Ahora podr√© darte respuestas m√°s personalizadas considerando esta informaci√≥n."
                    
                    return {"answer": response_text, "usage": {}}
                    
                except Exception as e:
                    print(f"Error guardando conocimiento confirmado: {e}")
                    confirmation_cache.clear_pending_confirmation(user_id)
                    return {"answer": "‚ùå Hubo un error guardando la informaci√≥n. Por favor intenta de nuevo.", "usage": {}}
                    
            else:  # Usuario rechaz√≥
                confirmation_cache.clear_pending_confirmation(user_id)
                return {"answer": "üëå Entendido, no guardar√© esa informaci√≥n.", "usage": {}}

    # Contexto RAG, perfiles/beb√©s e historial de conversaci√≥n
    rag_context = await get_rag_context(payload.message)
    user_context, routines_context = await get_user_profiles_and_babies(user["id"], supabase)
    history = await get_conversation_history(user["id"], supabase)  # üëà historial del backend


    print(f"üìö Contexto RAG recuperado:\n{rag_context[:500]}...\n")
    
    # Prompt de sistema
    system_prompt = (
        "Eres un acompa√±ante cercano para madres y padres. Tu nombre es Lumi. "
        "Responde de forma c√°lida, breve y coloquial, usando ejemplos simples y naturales. "
        "Si hay informaci√≥n en el contexto de documentos, √∫sala de manera expl√≠cita en tu respuesta. "
        "Nunca inventes informaci√≥n fuera de los documentos, solo completa con empat√≠a si el contexto no tiene la respuesta. "
        "No empieces siempre tus respuestas con 'Hola' o saludos, salvo que el usuario te salude primero. "
        "Si el usuario solo saluda, responde tambi√©n con un saludo corto y amistoso, sin consejos extra. "
        "Evita sonar acad√©mico o demasiado formal. "
        f"La fecha de hoy es {today}. Si el usuario pregunta por la fecha actual, responde con esta. "
        "Cuando alguien te hace una consulta sobre crianza, empieza por considerar la edad exacta del ni√±o o ni√±a, "
        "ya que esto define qu√© comportamientos son esperables y c√≥mo acompa√±arlos. "
        "Explica brevemente por qu√© ocurre lo que pasa, desde el desarrollo emocional, neurol√≥gico o conductual, "
        "para que el adulto entienda el trasfondo y no solo el s√≠ntoma. "
        "Si faltan datos importantes, p√≠delos antes de avanzar. "
        "A partir de ah√≠, propone estrategias concretas y realistas, siempre desde una mirada respetuosa "
        "que prioriza el v√≠nculo y la seguridad emocional. "
        "Cuando corresponda, incluye ejemplos de frases que ayuden a poner en palabras lo que ocurre. "
        "Termina tus respuestas con una pregunta abierta que permita seguir ajustando la gu√≠a a la situaci√≥n real. "
        "La idea no es dar f√≥rmulas m√°gicas, sino acompa√±ar a construir respuestas que tengan sentido y funcionen en la familia."
    )


    # Formatear el perfil que viene en el payload
    profile_text = ""
    if payload.profile:
        profile_data = payload.profile
        profile_text = (
            "Perfil actual:\n"
            f"- Fecha de nacimiento: {profile_data.get('dob')}\n"
            f"- Alimentaci√≥n: {profile_data.get('feeding')}\n"
        )

    # Construcci√≥n del body con separaci√≥n clara de roles
    body = {
        "model": OPENAI_MODEL,
        "messages": [
            {"role": "system", "content": system_prompt},
            {"role": "system", "content": f"Contexto de usuario:\n{user_context}"},
            {"role": "system", "content": f"Contexto del perfil enviado:\n{profile_text}"},
            {"role": "system", "content": f"Contexto de rutinas:\n{routines_context}"},
            {"role": "system", "content": f"Usa estrictamente la siguiente informaci√≥n del libro si es relevante:\n\n{rag_context}"},
            *history,  
            {"role": "user", "content": payload.message},
        ],
        "max_tokens": 1000,
        "temperature": 0.3,
    }

    headers = {"Authorization": f"Bearer {OPENAI_KEY}", "Content-Type": "application/json"}

    async with httpx.AsyncClient(timeout=30.0) as client:
        resp = await client.post("https://api.openai.com/v1/chat/completions", json=body, headers=headers)

    if resp.status_code >= 300:
        raise HTTPException(status_code=502, detail={"openai_error": resp.text})

    data = resp.json()
    assistant = data.get("choices", [])[0].get("message", {}).get("content", "")
    usage = data.get("usage", {})

    # NUEVA FUNCIONALIDAD: Detectar conocimiento importante en el mensaje del usuario
    try:
        print(f"üîç Analizando mensaje para conocimiento: {payload.message}")
        
        # Obtener informaci√≥n de beb√©s para el contexto
        babies = supabase.table("babies").select("*").eq("user_id", user_id).execute()
        babies_context = babies.data or []
        print(f"üë∂ Beb√©s encontrados: {len(babies_context)}")
        
        # Analizar el mensaje para detectar informaci√≥n importante
        detected_knowledge = await KnowledgeDetector.analyze_message(
            payload.message, 
            babies_context
        )
        print(f"üß† Conocimiento detectado: {detected_knowledge}")
        
        # Si se detecta conocimiento importante, guardar en cach√© y preguntar
        if detected_knowledge and KnowledgeDetector.should_ask_confirmation(detected_knowledge):
            print("‚úÖ Se debe preguntar confirmaci√≥n")
            
            # Guardar en cach√© para confirmaci√≥n posterior
            confirmation_cache.set_pending_confirmation(user_id, detected_knowledge, payload.message)
            
            confirmation_message = KnowledgeDetector.format_confirmation_message(detected_knowledge)
            
            # Agregar la pregunta de confirmaci√≥n a la respuesta
            assistant_with_confirmation = f"{assistant}\n\nüí° {confirmation_message}"
            
            return {
                "answer": assistant_with_confirmation, 
                "usage": usage
            }
        else:
            print("‚ùå No se debe preguntar confirmaci√≥n")
        
    except Exception as e:
        print(f"Error en detecci√≥n de conocimiento: {e}")
        import traceback
        traceback.print_exc()
        # Continuar normalmente si falla la detecci√≥n
        pass

    return {"answer": assistant, "usage": usage}

@router.get("/api/test-knowledge")
async def test_knowledge():
    """
    Endpoint de prueba para verificar que el sistema funciona
    """
    return {
        "message": "Sistema de conocimiento funcionando",
        "detector_available": "KnowledgeDetector" in globals(),
        "service_available": "BabyKnowledgeService" in globals()
    }

@router.get("/api/test-cache/{user_id}")
async def test_cache(user_id: str):
    """
    Endpoint de prueba para ver el estado del cach√©
    """
    pending = confirmation_cache.get_pending_confirmation(user_id)
    return {
        "has_pending": confirmation_cache.has_pending_confirmation(user_id),
        "pending_data": pending
    }

@router.post("/api/test-detect")
async def test_detect(payload: ChatRequest, user=Depends(get_current_user)):
    """
    Endpoint de prueba para probar solo la detecci√≥n de conocimiento
    """
    try:
        # Obtener informaci√≥n de beb√©s para el contexto
        babies = supabase.table("babies").select("*").eq("user_id", user["id"]).execute()
        babies_context = babies.data or []
        
        # Analizar el mensaje para detectar informaci√≥n importante
        detected_knowledge = await KnowledgeDetector.analyze_message(
            payload.message, 
            babies_context
        )
        
        return {
            "message": payload.message,
            "babies_found": len(babies_context),
            "babies_names": [b.get('name', '') for b in babies_context],
            "detected_knowledge": detected_knowledge,
            "should_confirm": KnowledgeDetector.should_ask_confirmation(detected_knowledge)
        }
        
    except Exception as e:
        import traceback
        traceback.print_exc()
        return {"error": str(e), "traceback": traceback.format_exc()}
