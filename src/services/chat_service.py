# src/services/chat_service.py
import json
import traceback
from datetime import datetime
from pathlib import Path
from ..rag.retriever import supabase
from ..services.knowledge_service import BabyKnowledgeService
from ..utils.knowledge_cache import confirmation_cache
from ..services.routine_service import RoutineService
from ..utils.routine_cache import routine_confirmation_cache
from ..utils.knowledge_detector import KnowledgeDetector

# Constantes necesarias para build_system_prompt
today = datetime.now().strftime("%d/%m/%Y %H:%M")

PROMPTS_DIR = Path(__file__).parent.parent / "prompts"
SECTIONS_DIR = PROMPTS_DIR / "sections"
TEMPLATES_DIR = PROMPTS_DIR / "templates"
EXAMPLES_DIR = Path(__file__).parent.parent / "examples" 

# Keywords copiadas de chat.py
ROUTINE_KEYWORDS = {
    "organizar rutina", "organizar la rutina", "ajustar horarios", "cambiar horarios",
    "estructurar el d√≠a", "horarios de comida", "horarios de sue√±o",
    "rutina de sue√±o", "orden del d√≠a", "cronograma", "planificar el d√≠a",
    "horarios del beb√©", "rutina diaria", "establecer rutina", "fijar horarios",
    "hacer una rutina", "hacer rutina", "quiero rutina", "crear rutina",
    "armar rutina", "armar una rutina", "necesito rutina", "rutina para",
    "una rutina para", "rutina", "horarios", "organizar el d√≠a"
}

NIGHT_WEANING_KEYWORDS = {
    "tomas nocturnas", "destete nocturno", "desmame nocturno", "disminuir tomas",
    "reducir tomas", "eliminar tomas nocturnas", "dormir sin mamar",
    "dormir toda la noche", "no despertar para comer", "destete gradual",
    "quitar toma nocturna", "destetar por la noche", "no alimentar de noche"
}

BEHAVIOR_KEYWORDS = {
    "berrinche", "berrinches", "rabieta", "rabietas", "llanto excesivo",
    "llanto intenso", "llanto sin raz√≥n", "lloriqueo", "capricho", "caprichos",
    "no obedece", "rebelde", "desafiante", "comportamiento dif√≠cil",
    "conducta", "disciplina", "l√≠mites", "reglas", "portarse mal",
    "mal comportamiento", "agresivo", "agresividad", "golpea", "muerde",
    "pega", "empuja", "no hace caso", "desobediente"
}

PARTNER_KEYWORDS = {
    "pareja", "pap√°", "pap√° no", "mi esposo", "mi marido", "mi novio",
    "mi pareja", "padre", "abuelo", "suegra", "suegro", "familia",
    "no entiende", "no ayuda", "discutimos", "diferencias", "conflicto",
    "apoyo", "involucrar", "participar", "roles", "responsabilidades"
}

def load_example_dataset():
    """
    Carga el dataset de ejemplos JSONL desde src/examples.
    Convierte las conversaciones JSON a formato texto para el system prompt.
    """
    dataset_path = EXAMPLES_DIR / "lumi_instruction_dataset_v1.jsonl"
    
    if not dataset_path.exists():
        print(f"‚ö†Ô∏è Dataset no encontrado: {dataset_path}")
        return ""
    
    header = "## DATASET DE EJEMPLOS LUMI (v1)\nUsar como gu√≠a de referencia para la generaci√≥n de respuestas.\n\n"
    
    try:
        examples_text = []
        with open(dataset_path, "r", encoding="utf-8") as jsonl_file:
            for line_num, line in enumerate(jsonl_file, 1):
                if line.strip():
                    data = json.loads(line)
                    if "messages" in data:
                        example_text = f"### Ejemplo {line_num}:\n"
                        for msg in data["messages"]:
                            role = msg.get("role", "unknown").upper()
                            content = msg.get("content", "").strip()
                            if content:
                                example_text += f"**{role}**: {content}\n\n"
                        examples_text.append(example_text)
        
        if examples_text:
            content = "\n".join(examples_text)
            print(f"üìö Cargados {len(examples_text)} ejemplos desde {dataset_path.name}")
            return header + content
        else:
            print(f"‚ö†Ô∏è No se pudieron cargar ejemplos desde {dataset_path.name}")
            return ""
                    
    except Exception as e:
        print(f"‚ùå Error cargando dataset JSONL: {e}")
        return ""

def load_base_system_prompt():
    """
    Carga solo el prompt base esencial, SIN ejemplos ni contexto din√°mico.
    Esto mantiene el system prompt peque√±o y estable.
    """
    candidate_paths = [
        PROMPTS_DIR / "system_prompt_base.md",
        PROMPTS_DIR / "system" / "system_prompt_base.md",
    ]

    base_path = next((path for path in candidate_paths if path.exists()), None)
    if not base_path:
        raise RuntimeError(
            "No se encontr√≥ el archivo base del prompt. "
            f"Rutas probadas: {', '.join(str(p) for p in candidate_paths)}"
        )

    with open(base_path, "r", encoding="utf-8") as f:
        base_content = f.read().strip()

    # Solo agregar reglas operacionales b√°sicas, NO ejemplos ni contexto din√°mico
    system_dir = base_path.parent
    operational_rules_path = system_dir / "system_operational_rules.md"
    
    if operational_rules_path.exists():
        with open(operational_rules_path, "r", encoding="utf-8") as f:
            base_content += "\n\n" + f.read().strip()

    return base_content

def build_dynamic_context(user_context: str, profile_text: str, routines_context: str, 
                         combined_rag_context: str, specific_sections: list = None):
    """
    Construye el contexto din√°mico que se enviar√° como parte del mensaje del usuario.
    Esto no cuenta contra el l√≠mite del system prompt.
    """
    context_parts = []
    
    # Informaci√≥n del usuario y beb√©s
    if user_context:
        context_parts.append(f"üìã INFORMACI√ìN DEL USUARIO:\n{user_context}")
    
    # Perfil de los beb√©s (resumido)
    if profile_text:
        # Truncar si es muy largo
        if len(profile_text) > 2000:
            profile_text = profile_text[:2000] + "\n... [Perfil truncado]"
        context_parts.append(f"üë∂ PERFIL DE LOS BEB√âS:\n{profile_text}")
    
    # Rutinas (resumidas)
    if routines_context:
        if len(routines_context) > 1500:
            routines_context = routines_context[:1500] + "\n... [Rutinas truncadas]"
        context_parts.append(f"üïê RUTINAS ESTABLECIDAS:\n{routines_context}")
    
    # Contexto RAG (limitado)
    if combined_rag_context:
        max_rag_length = 3000  # Reducido de 10000
        if len(combined_rag_context) > max_rag_length:
            combined_rag_context = combined_rag_context[:max_rag_length] + "\n... [Contexto RAG truncado]"
        context_parts.append(f"üìö CONOCIMIENTO RELEVANTE:\n{combined_rag_context}")
    
    # Secciones espec√≠ficas (comportamiento, rutinas, etc.)
    if specific_sections:
        sections_text = load_specific_sections(specific_sections)
        if sections_text:
            context_parts.append(f"üéØ GU√çAS ESPEC√çFICAS:\n{sections_text}")
    
    return "\n\n".join(context_parts) if context_parts else ""

def load_specific_sections(section_files: list) -> str:
    """Carga secciones espec√≠ficas de forma compacta"""
    if not section_files:
        return ""
    
    parts = []
    seen = set()
    
    for filename in section_files:
        if filename in seen:
            continue
        seen.add(filename)
        
        section_path = SECTIONS_DIR / filename
        if section_path.exists():
            with open(section_path, "r", encoding="utf-8") as f:
                content = f.read().strip()
                # Limitar tama√±o de cada secci√≥n
                if len(content) > 800:
                    content = content[:800] + "\n... [Secci√≥n truncada]"
                parts.append(f"### {filename.replace('.md', '').title()}\n{content}")
    
    return "\n\n".join(parts)
    """
        Carga el prompt base y concatena secciones adicionales seg√∫n sea necesario.
        `section_files` debe ser una lista de nombres de archivo (por ejemplo, ["style.md"]).
    """
    candidate_paths = [
        PROMPTS_DIR / "system_prompt_base.md",
        PROMPTS_DIR / "system" / "system_prompt_base.md",
    ]

    base_path = next((path for path in candidate_paths if path.exists()), None)
    if not base_path:
        raise RuntimeError(
            "No se encontr√≥ el archivo base del prompt. "
            f"Rutas probadas: {', '.join(str(p) for p in candidate_paths)}"
        )

    with open(base_path, "r", encoding="utf-8") as f:
        parts = [f.read().strip()]

    system_dir = base_path.parent
    additional_system_files = [
        "system_operational_rules.md",
        "system_style_guide.md",
    ]

    for filename in additional_system_files:
        system_path = system_dir / filename
        if system_path.exists():
            with open(system_path, "r", encoding="utf-8") as system_file:
                parts.append(system_file.read().strip())
        else:
            print(f"‚ö†Ô∏è Archivo de sistema no encontrado: {system_path}")

    if section_files:
        seen = set()
        for filename in section_files:
            if filename in seen:
                continue
            seen.add(filename)
            section_path = SECTIONS_DIR / filename
            if section_path.exists():
                with open(section_path, "r", encoding="utf-8") as section_file:
                    parts.append(section_file.read().strip())
            else:
                print(f"‚ö†Ô∏è Secci√≥n de prompt no encontrada: {section_path}")

    return "\n\n".join(parts)

def detect_consultation_type_and_load_template(message):
    """
        Detecta el tipo de consulta y carga el template espec√≠fico correspondiente.
    """
    message_lower = message.lower()
    
    # Mapeo de tipos de consulta y sus templates correspondientes
    consultation_types = {
        "pediatra": ["quiero ir al pediatra", "llevar al pediatra", "consulta m√©dica", 
                    "visita m√©dica", "cita con el doctor", "ir al doctor"],
        "feeding": ["no quiere comer", "problemas para comer", "rechazo comida", 
                   "alimentaci√≥n", "blw", "baby led weaning", "destete"],
        "sleep": ["no duerme", "problemas de sue√±o", "dormir", "sue√±o", "insomnio beb√©", 
                 "despertar nocturno", "regresi√≥n del sue√±o"],
        "development": ["desarrollo", "hitos", "cu√°ndo camina", "cu√°ndo habla", 
                       "gatear", "sentarse", "primeras palabras"]
    }
    
    # Detectar tipo de consulta
    detected_type = None
    for consultation_type, keywords in consultation_types.items():
        if any(keyword in message_lower for keyword in keywords):
            detected_type = consultation_type
            break
    
    if not detected_type:
        return ""
    
    # Buscar template correspondiente
    template_path = TEMPLATES_DIR / f"{detected_type}.md"
    
    if template_path.exists():
        with open(template_path, "r", encoding="utf-8") as template_file:
            template_content = template_file.read().strip()
            return f"\n\n## TEMPLATE ESPEC√çFICO - {detected_type.upper()}\n{template_content}"
    
    return ""

def build_chat_prompt(base_system_prompt: str, dynamic_context: str, history: list, user_message: str):
    """
    Construye un prompt estructurado para Lumi optimizado para reducir tokens del system prompt.
    Separa el prompt base (est√°tico) del contexto din√°mico (perfiles, RAG, etc.)
    """
    
    # System prompt solo con instrucciones b√°sicas (m√°s peque√±o)
    messages = [
        {"role": "system", "content": base_system_prompt}
    ]
    
    # Contexto din√°mico como mensaje del usuario (no cuenta como system prompt)
    if dynamic_context:
        messages.append({
            "role": "user", 
            "content": f"CONTEXTO PARA ESTA CONSULTA:\n{dynamic_context}\n\n---\n\nMi consulta real es: {user_message}"
        })
    else:
        messages.append({"role": "user", "content": user_message})
    
    # Agregar historial si existe (con l√≠mite)
    if history:
        # Limitar historial a los √∫ltimos N mensajes para reducir tokens
        recent_history = history[-6:] if len(history) > 6 else history
        messages.extend(recent_history)
    
    return messages

async def handle_knowledge_confirmation(user_id: str, message: str):
    """
    Maneja la confirmaci√≥n de conocimiento pendiente.
    Retorna None si no hay confirmaci√≥n pendiente, o la respuesta si la hay.
    """
    confirmation_response = confirmation_cache.is_confirmation_response(message)
    if confirmation_response is None or not confirmation_cache.has_pending_confirmation(user_id):
        return None

    print(f"üéØ Detectada respuesta de confirmaci√≥n de conocimiento: {confirmation_response}")

    pending_data = confirmation_cache.get_pending_confirmation(user_id)
    if not pending_data:
        return None

    if confirmation_response:
        try:
            saved_items = []

            for knowledge_item in pending_data["knowledge"]:
                baby_id = await BabyKnowledgeService.find_baby_by_name(
                    user_id,
                    knowledge_item.get("baby_name", ""),
                )

                if baby_id:
                    knowledge_data = {
                        "category": knowledge_item["category"],
                        "subcategory": knowledge_item.get("subcategory"),
                        "title": knowledge_item["title"],
                        "description": knowledge_item["description"],
                        "importance_level": knowledge_item.get("importance_level", 1),
                    }

                    saved_item = await BabyKnowledgeService.save_knowledge(
                        user_id,
                        baby_id,
                        knowledge_data,
                    )
                    saved_items.append(saved_item)

            confirmation_cache.clear_pending_confirmation(user_id)

            response_text = (
                f"‚úÖ ¬°Perfecto! He guardado {len(saved_items)} elemento(s) en el perfil. "
                "Ahora podr√© darte respuestas m√°s personalizadas considerando esta informaci√≥n."
            )

            return {"answer": response_text, "usage": {}}

        except Exception as e:
            print(f"Error guardando conocimiento confirmado: {e}")
            confirmation_cache.clear_pending_confirmation(user_id)
            return {
                "answer": "‚ùå Hubo un error guardando la informaci√≥n. Por favor intenta de nuevo.",
                "usage": {},
            }

    confirmation_cache.clear_pending_confirmation(user_id)
    return {"answer": "üëå Entendido, no guardar√© esa informaci√≥n.", "usage": {}}

async def handle_routine_confirmation(user_id: str, message: str):
    """
    Maneja la confirmaci√≥n de rutinas pendientes.
    Retorna None si no hay confirmaci√≥n pendiente, o la respuesta si la hay.
    """
    routine_confirmation_response = routine_confirmation_cache.is_confirmation_response(message)
    if routine_confirmation_response is None or not routine_confirmation_cache.has_pending_confirmation(user_id):
        return None

    print(f"üéØ Detectada respuesta de confirmaci√≥n de rutina: {routine_confirmation_response}")
    
    pending_routine_data = routine_confirmation_cache.get_pending_confirmation(user_id)
    if not pending_routine_data:
        return None

    if routine_confirmation_response:  # Usuario confirm√≥ la rutina
        try:
            routine_data = pending_routine_data["routine"]
            
            # Buscar el baby_id basado en el nombre
            baby_id = await RoutineService.find_baby_by_name(
                user_id, 
                routine_data.get("baby_name", "")
            )
            
            if baby_id:
                # 1. GUARDAR LA RUTINA en tablas espec√≠ficas
                saved_routine = await RoutineService.save_routine(
                    user_id, 
                    baby_id, 
                    routine_data
                )
                
                # 2. TAMBI√âN GUARDAR COMO CONOCIMIENTO GENERAL
                try:
                    routine_name = routine_data.get("routine_name", "Rutina")
                    routine_summary = routine_data.get("context_summary", "Rutina establecida")
                    
                    # Crear entrada de conocimiento basada en la rutina
                    knowledge_data = {
                        "category": "rutinas",
                        "subcategory": "estructura diaria",
                        "title": routine_name,
                        "description": routine_summary,
                        "importance_level": 3
                    }
                    
                    # Guardar tambi√©n en baby_knowledge
                    await BabyKnowledgeService.save_knowledge(
                        user_id, 
                        baby_id, 
                        knowledge_data
                    )
                    
                    print(f"‚úÖ Rutina guardada en AMBOS sistemas: rutinas + conocimiento")
                    
                except Exception as knowledge_error:
                    print(f"‚ö†Ô∏è Error guardando conocimiento de rutina: {knowledge_error}")
                    # No fallar si el conocimiento falla, la rutina ya se guard√≥
                
                routine_confirmation_cache.clear_pending_confirmation(user_id)
                
                activities_count = saved_routine.get("activities_count", 0)
                
                response_text = f"‚úÖ ¬°Excelente! He guardado la rutina **{routine_name}** con {activities_count} actividades en el sistema de rutinas y tambi√©n como conocimiento general. Ahora podr√© ayudarte mejor con horarios y sugerencias personalizadas."
                
                return {"answer": response_text, "usage": {}}
            else:
                routine_confirmation_cache.clear_pending_confirmation(user_id)
                return {"answer": "‚ùå No pude encontrar el beb√© mencionado. Por favor intenta de nuevo.", "usage": {}}
                
        except Exception as e:
            print(f"Error guardando rutina confirmada: {e}")
            routine_confirmation_cache.clear_pending_confirmation(user_id)
            return {"answer": "‚ùå Hubo un error guardando la rutina. Por favor intenta de nuevo.", "usage": {}}
            
    else:  # Usuario rechaz√≥ la rutina
        routine_confirmation_cache.clear_pending_confirmation(user_id)
        return {"answer": "üëå Entendido, no guardar√© esa rutina.", "usage": {}}


async def detect_routine_in_response(user_id: str, assistant_response: str, babies_context: list):
    """
    Detecta rutinas estructuradas en la respuesta de Lumi usando m√©todo simple.
    Retorna None si no se detecta rutina, o mensaje de confirmaci√≥n si se detecta.
    """
    try:
        print(f"üîç Analizando respuesta de Lumi para rutinas (m√©todo simple)...")
        
        # 1. Detectar horarios estructurados
        import re
        time_patterns = re.findall(r'\*\*\d{1,2}:\d{2}[‚Äì-]\d{1,2}:\d{2}\*\*', assistant_response)
        
        # 2. Detectar palabras clave de rutina
        routine_indicators = [
            "rutina diaria", "rutina para", "üß≠", "üåÖ", "ma√±ana", "mediod√≠a", "tarde", "noche",
            "despertar", "desayuno", "almuerzo", "siesta", "cena", "ba√±o",
            "resumen visual", "bloques", "actividad principal"
        ]
        found_indicators = sum(1 for indicator in routine_indicators if indicator in assistant_response.lower())
        
        # 3. Criterios simples para detectar rutina
        has_structured_times = len(time_patterns) >= 3
        has_routine_content = found_indicators >= 5
        
        print(f"‚è∞ Horarios encontrados: {len(time_patterns)}")
        print(f"üìã Indicadores de rutina: {found_indicators}")
        print(f"üéØ Es rutina estructurada: {has_structured_times and has_routine_content}")
        
        if has_structured_times and has_routine_content:
            print("‚úÖ Rutina detectada con m√©todo simple - Agregando confirmaci√≥n")
            
            # Obtener informaci√≥n de beb√©s
            baby_name = babies_context[0]['name'] if babies_context else "tu beb√©"
            
            # Crear rutina simple estructurada
            simple_routine = {
                "routine_name": f"Rutina diaria para {baby_name}",
                "baby_name": baby_name,
                "confidence": 0.9,  # Alta confianza para m√©todo simple
                "routine_type": "daily",
                "context_summary": "Rutina diaria detectada autom√°ticamente",
                "activities": [
                    {
                        "time_start": pattern.replace('*', '').split('‚Äì')[0],
                        "time_end": pattern.replace('*', '').split('‚Äì')[1] if '‚Äì' in pattern else None,
                        "activity": f"Actividad {i+1}",
                        "details": "Actividad detectada autom√°ticamente",
                        "activity_type": "care"
                    }
                    for i, pattern in enumerate(time_patterns[:10])  # M√°ximo 10 actividades
                ]
            }
            
            # Guardar en cach√© y pedir confirmaci√≥n
            routine_confirmation_cache.set_pending_confirmation(user_id, simple_routine, assistant_response)
            
            confirmation_message = f"¬øTe parece si guardo esta rutina para {baby_name} en su perfil para futuras conversaciones?"
            return confirmation_message
        else:
            print("‚ùå No es una rutina estructurada seg√∫n criterios simples")
            return None
            
    except Exception as e:
        print(f"Error en detecci√≥n simple de rutinas: {e}")
        return None

async def detect_knowledge_in_message(user_id: str, message: str, babies_context: list, selected_baby_id: str = None):
    """
    Detecta conocimiento importante en el mensaje del usuario.
    Retorna None si no se detecta conocimiento, o mensaje de confirmaci√≥n si se detecta.
    """
    try:
        print(f"üß† Analizando mensaje para conocimiento: {message}")
        
        # Analizar el mensaje para detectar informaci√≥n importante
        detected_knowledge = await KnowledgeDetector.analyze_message(
            message, 
            babies_context
        )
        print(f"üß† Conocimiento detectado: {detected_knowledge}")

        # Enriquecer nombres gen√©ricos con nombres reales del contexto
        KnowledgeDetector.enrich_baby_names(
            detected_knowledge,
            babies_context=babies_context,
            original_message=message
        )

        # Guardar autom√°ticamente conocimiento general sin confirmaci√≥n
        general_items = [item for item in detected_knowledge if item.get("category") == "general"]
        for general_item in general_items:
            baby_name = general_item.get("baby_name")
            auto_baby_id = None

            if baby_name:
                auto_baby_id = await BabyKnowledgeService.find_baby_by_name(user_id, baby_name)

            if not auto_baby_id and selected_baby_id:
                auto_baby_id = selected_baby_id

            if not auto_baby_id and babies_context:
                auto_baby_id = babies_context[0]["id"]

            if not auto_baby_id:
                print(f"‚ö†Ô∏è No se pudo determinar beb√© para conocimiento general: {general_item}")
                continue

            knowledge_payload = {
                "category": general_item["category"],
                "subcategory": general_item.get("subcategory"),
                "title": general_item.get("title", general_item.get("description", "Contexto general")),
                "description": general_item.get("description", general_item.get("title", "")),
                "importance_level": general_item.get("importance_level", 2)
            }

            saved_general = await BabyKnowledgeService.save_or_update_general_knowledge(
                user_id,
                auto_baby_id,
                knowledge_payload
            )

            if saved_general:
                print(f"üè† Conocimiento general guardado autom√°ticamente: {knowledge_payload['title']} (baby_id={auto_baby_id})")
            else:
                print(f"‚ö†Ô∏è No se pudo guardar conocimiento general: {knowledge_payload}")

        # Filtrar conocimientos generales para no pedir confirmaci√≥n
        detected_knowledge = [item for item in detected_knowledge if item.get("category") != "general"]
        
        # Si se detecta conocimiento importante, guardar en cach√© y preguntar
        if detected_knowledge and KnowledgeDetector.should_ask_confirmation(detected_knowledge):
            print("‚úÖ Se debe preguntar confirmaci√≥n")
            
            # Guardar en cach√© para confirmaci√≥n posterior
            confirmation_cache.set_pending_confirmation(user_id, detected_knowledge, message)
            
            confirmation_message = KnowledgeDetector.format_confirmation_message(detected_knowledge)
            return confirmation_message
        else:
            print("‚ùå No se debe preguntar confirmaci√≥n de conocimiento")
            return None
        
    except Exception as e:
        print(f"Error en detecci√≥n de conocimiento: {e}")
        import traceback
        traceback.print_exc()
        return None

async def get_baby_profile(user_id: str, baby_id: str = None):
    """
    Obtiene informaci√≥n detallada de un beb√© espec√≠fico del usuario incluyendo su perfil
    desde las tablas babies, baby_profile, baby_profile_value y profile_category.
    
    Args:
        user_id: ID del usuario
        baby_id: ID espec√≠fico del beb√© (opcional). Si no se proporciona, retorna el primer beb√©.
    
    Retorna:
        Diccionario con informaci√≥n del beb√© espec√≠fico y su perfil detallado por categor√≠as.
        Ejemplo de estructura retornada:
        {
            "id": "uuid",
            "name": "Jacinta", 
            "birthdate": "2025-05-08",
            "gender": "female",
            "profile": {
                "sleep and rest": {
                    "sleep_location": {"value_es": "cuna", "value_en": "crib"},
                    "day_night_difference": {"value_es": "comienza a distinguir", "value_en": "starting to distinguish"}
                },
                "daily cares": {
                    "dental_care_type": {"value_es": "pasta sin fl√∫or", "value_en": "toothpaste without fluoride"}
                }
            }
        }
        
        Retorna None si no se encuentra el beb√© espec√≠fico.
    """
    try:
        # Usar funci√≥n RPC optimizada para obtener beb√©s con perfil completo
        response = supabase.rpc('get_babies_with_profile_data', {
            'p_user_id': user_id
        }).execute()
        
        if response.data is None:
            print(f"üë∂ No se encontraron beb√©s para user_id: {user_id}")
            return None
        
        babies_data = response.data
        
        # Si se especific√≥ un baby_id, buscar ese beb√© espec√≠fico
        if baby_id:
            selected_baby = next((baby for baby in babies_data if baby.get('id') == baby_id), None)
            if selected_baby:
                print(f"üë∂ Obtenido perfil del beb√© espec√≠fico: {selected_baby.get('name', 'Sin nombre')} (ID: {baby_id})")
                return selected_baby
            else:
                print(f"‚ö†Ô∏è No se encontr√≥ beb√© con ID: {baby_id} para user_id: {user_id}")
                # Fallback al primer beb√© si el baby_id no se encuentra
                if babies_data:
                    first_baby = babies_data[0]
                    print(f"üîÑ Usando primer beb√© disponible: {first_baby.get('name', 'Sin nombre')} (ID: {first_baby.get('id')})")
                    return first_baby
                return None
        else:
            # Si no se especific√≥ baby_id, usar el primer beb√© disponible
            if babies_data:
                first_baby = babies_data[0]
                print(f"üë∂ Usando primer beb√© disponible: {first_baby.get('name', 'Sin nombre')} (ID: {first_baby.get('id')})")
                return first_baby
            
        print(f"üë∂ No se encontraron beb√©s para user_id: {user_id}")
        return None
        
    except Exception as e:
        print(f"‚ùå Error al obtener el perfil del beb√©: {e}")
        import traceback
        traceback.print_exc()
        return None

def format_baby_profile_for_context(baby_data, lang: str = 'es') -> str:
    """
    Formatea la informaci√≥n de perfil de un beb√© espec√≠fico para incluir en el system prompt.
    
    Args:
        baby_data: Puede ser un diccionario con informaci√≥n de un beb√© individual, 
                  o una lista de beb√©s (para mantener compatibilidad)
        lang: Idioma para mostrar los valores ('es', 'en', 'pt')
    
    Returns:
        String formateado con la informaci√≥n de perfil del beb√© espec√≠fico
    """
    # Manejar tanto un beb√© individual como una lista de beb√©s
    if baby_data is None:
        return "No hay informaci√≥n de perfil disponible."
    
    if isinstance(baby_data, dict):
        # Es un beb√© individual
        babies_data = [baby_data]
    elif isinstance(baby_data, list):
        # Es una lista de beb√©s (compatibilidad)
        babies_data = baby_data
    else:
        return "Formato de datos de beb√© no v√°lido."
    
    if not babies_data:
        return "No hay informaci√≥n de perfil disponible."
    
    formatted_profiles = []
    
    for baby in babies_data:
        baby_name = baby.get('name', 'Beb√© sin nombre')
        baby_age = baby.get('birthdate', '')
        profile_data = baby.get('profile', {})
        
        if not profile_data:
            # Si no hay perfil, al menos mostrar informaci√≥n b√°sica
            formatted_profiles.append(f"üë∂ **{baby_name}** ({baby_age}) - Sin perfil detallado disponible")
            continue
        
        baby_profile_lines = [f"üë∂ **{baby_name}** ({baby_age})"]
        
        for category, category_data in profile_data.items():
            if category_data:  # Solo mostrar si hay datos
                baby_profile_lines.append(f"  üìÇ {category.title()}:")
                
                for key, values in category_data.items():
                    # Obtener valor en el idioma especificado, con fallback a espa√±ol
                    value_key = f'value_{lang}'
                    display_value = values.get(value_key) or values.get('value_es') or 'N/A'
                    
                    # Formatear key para que sea m√°s legible
                    formatted_key = key.replace('_', ' ').title()
                    baby_profile_lines.append(f"    ‚Ä¢ {formatted_key}: {display_value}")
        
        if len(baby_profile_lines) > 1:  # Solo agregar si tiene contenido adem√°s del nombre
            formatted_profiles.append('\n'.join(baby_profile_lines))
    
    if formatted_profiles:
        # Usar singular si es un solo beb√©, plural si son m√∫ltiples
        header = "## PERFIL DETALLADO DEL BEB√â:" if len(babies_data) == 1 else "## PERFILES DETALLADOS DE LOS BEB√âS:"
        return header + "\n\n" + '\n\n'.join(formatted_profiles)
    else:
        return "El beb√© no tiene informaci√≥n de perfil detallada disponible."

async def build_system_prompt(payload, user_context, routines_context, combined_rag_context, user_id=None, baby_id=None):
    """
    Construye el prompt del sistema OPTIMIZADO - separa contenido base de contexto din√°mico.
    Retorna tanto el system prompt base como el contexto din√°mico por separado.
    
    Args:
        payload: Objeto de request con el mensaje del usuario
        user_context: Contexto general del usuario
        routines_context: Contexto de rutinas
        combined_rag_context: Contexto de knowledge/RAG
        user_id: ID del usuario
        baby_id: ID espec√≠fico del beb√© (opcional). Si no se proporciona, usa el primer beb√© disponible.
    """
    message_lower = payload.message.lower()
    
    # Determinar qu√© secciones espec√≠ficas necesitamos
    needed_sections = []
    if any(keyword in message_lower for keyword in BEHAVIOR_KEYWORDS):
        needed_sections.append("behavior.md")
    if any(keyword in message_lower for keyword in ROUTINE_KEYWORDS):
        needed_sections.append("routines.md")
    if any(keyword in message_lower for keyword in NIGHT_WEANING_KEYWORDS):
        needed_sections.append("night_weaning.md")
    if any(keyword in message_lower for keyword in PARTNER_KEYWORDS):
        needed_sections.append("partner_support.md")

    # 1. SYSTEM PROMPT BASE (peque√±o y est√°tico)
    base_system_prompt = load_base_system_prompt()
    
    # Agregar template espec√≠fico al system prompt si es necesario
    specific_template = detect_consultation_type_and_load_template(payload.message)
    if specific_template:
        base_system_prompt += specific_template
        print(f"üéØ Template espec√≠fico agregado al system prompt")

    # 2. CONTEXTO DIN√ÅMICO (se enviar√° como parte del mensaje del usuario)
    profile_text = ""
    if user_id:
        try:
            # Obtener perfil del beb√© espec√≠fico si se proporciona baby_id
            baby_with_profile = await get_baby_profile(user_id, baby_id)
            if baby_with_profile:
                profile_text = format_baby_profile_for_context(baby_with_profile, lang='es')
                baby_name = baby_with_profile.get('name', 'Beb√©')
                baby_selected_id = baby_with_profile.get('id', baby_id or 'N/A')
                print(f"‚úÖ Perfil de beb√© espec√≠fico cargado: {baby_name} (ID: {baby_selected_id})")
            else:
                print(f"‚ö†Ô∏è No se pudo cargar perfil del beb√© (user_id: {user_id}, baby_id: {baby_id})")
        except Exception as e:
            print(f"‚ùå Error obteniendo perfil del beb√©: {e}")

    # Agregar perfil b√°sico del payload como fallback
    if payload.profile and not profile_text:
        profile_data = payload.profile
        profile_text = f"Fecha de nacimiento: {profile_data.get('dob', 'N/A')}"

    # Construir contexto din√°mico optimizado
    dynamic_context = build_dynamic_context(
        user_context=user_context,
        profile_text=profile_text,
        routines_context=routines_context,
        combined_rag_context=combined_rag_context,
        specific_sections=needed_sections
    )

    # Log de tama√±os para optimizaci√≥n
    base_length = len(base_system_prompt)
    dynamic_length = len(dynamic_context)
    print(f"üìè System prompt base: {base_length} caracteres")
    print(f"üìè Contexto din√°mico: {dynamic_length} caracteres")
    print(f"ÔøΩ Total optimizado: {base_length + dynamic_length}")

    return {
        "base_system_prompt": base_system_prompt,
        "dynamic_context": dynamic_context,
        "metadata": {
            "base_prompt_length": base_length,
            "dynamic_context_length": dynamic_length,
            "sections": needed_sections,
            "optimization_ratio": (base_length + dynamic_length) / 29273  # Comparaci√≥n con el anterior
        }
    }
